{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "orig_nbformat": 2,
    "kernelspec": {
      "name": "python385jvsc74a57bd0916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1",
      "display_name": "Python 3.8.5 64-bit"
    },
    "metadata": {
      "interpreter": {
        "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
      }
    },
    "colab": {
      "name": "Resnet_PIE_training.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rWB5GR2Vl00C"
      },
      "source": [
        "# PIE TRAINING"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CSZff1sJ6men",
        "outputId": "22364d64-b446-46a8-f4ae-73e596fd8b00"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EdxFk84_l00K"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NABBRcFul00L"
      },
      "source": [
        "import os\n",
        "os.chdir('/content/drive/Shareddrives/eecs442/PIE_PACK')\n",
        "from pie_data import PIE\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.models as models\n",
        "import pickle\n",
        "import cv2\n",
        "import sys\n",
        "\n",
        "import xml.etree.ElementTree as ET\n",
        "import numpy as np\n",
        "\n",
        "from os.path import join, abspath, isfile, isdir\n",
        "from os import makedirs, listdir\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from matplotlib import pyplot as plt\n",
        "import pylab\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, models, transforms\n",
        "from torch.utils.data.dataset import Dataset\n",
        "from torchsummary import summary\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import math\n",
        "import random"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18x-JBDFl00M",
        "outputId": "09b30a9a-e3fa-43a9-8147-7d8694511a73"
      },
      "source": [
        "if torch.cuda.is_available():\n",
        "    print(\"Using the GPU. You are good to go!\")\n",
        "    device = torch.device('cuda:0')\n",
        "else:\n",
        "    raise Exception(\"WARNING: Could not find GPU! Using CPU only. \\\n",
        "To enable GPU, please to go Edit > Notebook Settings > Hardware \\\n",
        "Accelerator and select GPU.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using the GPU. You are good to go!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t9J7T4OAl00N"
      },
      "source": [
        "##############################################################################\n",
        "# TODO: Adjust Sequence size and batch_size for loaders                      #\n",
        "##############################################################################\n",
        "SEQUENCE_SIZE = 20\n",
        "BATCH_SIZE = 10\n",
        "pie_path = '.'\n",
        "imdb = PIE(data_path=pie_path, regen_database=True, include_set=\"1,2,5,6\", frinterval=1, downsample=1600)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CNS7hINyl00N"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4V2_0rSkl00O",
        "outputId": "8130d878-3b33-4bf8-e0d3-3cb755a2f10b"
      },
      "source": [
        "class PedDataset(Dataset):\n",
        "    def __init__(self, ped_personal_images_intention, data_range=(0, 1)):\n",
        "        self.dataset = ped_personal_images_intention[data_range[0]:data_range[1]]\n",
        "        for index in range(len(self.dataset)):\n",
        "          self.dataset[index]=(self.dataset[index][0],self.dataset[index][1])\n",
        "        print(\"load dataset done\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img_seq, label = self.dataset[index]\n",
        "        seq_tensor = torch.stack(img_seq).cuda()\n",
        "        label = int(label > 0.5)\n",
        "        return torch.cuda.FloatTensor(seq_tensor), torch.tensor(label).cuda()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class PedDataset(Dataset):\n",
        "    def __init__(self, ped_personal_images_intention, data_range=(0, 1)):\n",
        "        self.dataset = ped_personal_images_intention[data_range[0]:data_range[1]]\n",
        "        for index in range(len(self.dataset)):\n",
        "          self.dataset[index]=(self.dataset[index][0],self.dataset[index][1])\n",
        "        print(\"load dataset done\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img_seq, label = self.dataset[index]\n",
        "        seq_tensor = torch.stack(img_seq).cuda()\n",
        "        label = int(label > 0.5)\n",
        "        return torch.cuda.FloatTensor(seq_tensor), torch.tensor(label).cuda()\n",
        "\n",
        "def get_ped_images_and_intention_v_colab(sequence_size=10, shuffle=True):\n",
        "    ped_personal_intention_prob = pd.read_csv(\"ped_personal_intention_prob.csv\")\n",
        "    ped_personal_images_intention = []\n",
        "    start = False\n",
        "    for root, dirs, files in os.walk(imdb._input_path):\n",
        "        print(root,len(ped_personal_images_intention))\n",
        "        if start:\n",
        "            temp_dir = []\n",
        "            index_file = 0\n",
        "            sequence_index = 0\n",
        "            num_files = len(os.listdir(root))\n",
        "            if num_files < sequence_size:\n",
        "                continue\n",
        "            files[:] = [int(float(x[:-4])) for x in files]\n",
        "            index_file = sorted(files)[0]\n",
        "            while sequence_index <sequence_size:\n",
        "                temp_dir.append((torch.from_numpy(cv2.imread(join(root, str(index_file)+\".png\")).astype(\"f\").transpose(2, 0, 1) / 128.0 - 1.0)))\n",
        "                index_file += 2*int(math.floor(num_files / sequence_size))\n",
        "                sequence_index += 1                    \n",
        "            # print(ped_personal_intention_prob[root[8:]])\n",
        "            ped_personal_images_intention.append((temp_dir, float(ped_personal_intention_prob[root[8:]])))\n",
        "        else:\n",
        "            start = True\n",
        "        \n",
        "    num_available_peds = len(ped_personal_images_intention)\n",
        "    print(num_available_peds)\n",
        "    if shuffle:\n",
        "        random.shuffle(ped_personal_images_intention)\n",
        "    return ped_personal_images_intention, num_available_peds\n",
        "\n",
        "ped_personal_images_intention, num_available_peds = get_ped_images_and_intention_v_colab(sequence_size=SEQUENCE_SIZE, shuffle=True)\n",
        "train_data = PedDataset(ped_personal_images_intention, data_range=(0, 200))\n",
        "train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
        "#TODO: Checkout the shuffle option for the DataLoader function\n",
        "val_data = PedDataset(ped_personal_images_intention, data_range=(200, 360))\n",
        "val_loader = DataLoader(val_data, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_data = PedDataset(ped_personal_images_intention, data_range=(360, 400))\n",
        "test_loader = DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=True)\n",
        "# test_data.__getitem__(0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "./input 0\n",
            "./input/5_2_1750 0\n",
            "./input/5_2_1751 1\n",
            "./input/5_2_1752 2\n",
            "./input/5_1_1747 3\n",
            "./input/5_1_1748 4\n",
            "./input/5_1_1749 4\n",
            "./input/5_1_1746 5\n",
            "./input/5_1_1744 6\n",
            "./input/5_1_1742 7\n",
            "./input/5_1_1745 8\n",
            "./input/5_1_1740 9\n",
            "./input/5_1_1739 9\n",
            "./input/5_1_1741 9\n",
            "./input/2_3_215 10\n",
            "./input/5_1_1731 11\n",
            "./input/2_3_217 12\n",
            "./input/5_1_1732 13\n",
            "./input/2_3_216 14\n",
            "./input/2_3_214 15\n",
            "./input/5_1_1733 16\n",
            "./input/2_3_212 17\n",
            "./input/2_3_211 18\n",
            "./input/2_3_213 19\n",
            "./input/2_3_207 20\n",
            "./input/2_3_205 21\n",
            "./input/2_3_208 22\n",
            "./input/2_3_210 23\n",
            "./input/2_3_206 24\n",
            "./input/2_3_204 25\n",
            "./input/2_3_209 26\n",
            "./input/2_3_203 27\n",
            "./input/2_3_201 28\n",
            "./input/2_3_202 29\n",
            "./input/2_3_197 30\n",
            "./input/2_3_198 31\n",
            "./input/2_3_194 32\n",
            "./input/2_3_200 33\n",
            "./input/2_3_195 34\n",
            "./input/2_3_199 35\n",
            "./input/2_3_196 36\n",
            "./input/2_2_191 37\n",
            "./input/2_2_193 38\n",
            "./input/2_2_192 39\n",
            "./input/2_2_186 40\n",
            "./input/2_2_185 41\n",
            "./input/2_2_190 42\n",
            "./input/2_2_188 43\n",
            "./input/2_2_187 44\n",
            "./input/2_2_184 45\n",
            "./input/2_2_189 46\n",
            "./input/2_2_183 47\n",
            "./input/2_2_182 48\n",
            "./input/2_2_181 49\n",
            "./input/2_2_176 50\n",
            "./input/2_2_178 51\n",
            "./input/2_2_180 52\n",
            "./input/2_2_177 53\n",
            "./input/2_2_179 54\n",
            "./input/2_2_175 55\n",
            "./input/2_2_174 56\n",
            "./input/2_2_172 57\n",
            "./input/2_2_171 58\n",
            "./input/2_2_173 59\n",
            "./input/2_2_164 60\n",
            "./input/2_2_165 61\n",
            "./input/2_2_167 62\n",
            "./input/2_2_166 63\n",
            "./input/2_2_169 64\n",
            "./input/2_2_170 65\n",
            "./input/2_2_168 66\n",
            "./input/2_2_160 67\n",
            "./input/2_2_161 68\n",
            "./input/2_2_163 69\n",
            "./input/2_2_157 70\n",
            "./input/2_2_158 71\n",
            "./input/2_2_159 72\n",
            "./input/2_2_150 73\n",
            "./input/2_2_153 74\n",
            "./input/2_2_152 75\n",
            "./input/2_2_155 76\n",
            "./input/2_2_151 77\n",
            "./input/2_2_154 78\n",
            "./input/2_2_156 79\n",
            "./input/2_2_149 80\n",
            "./input/2_2_148 81\n",
            "./input/2_2_147 82\n",
            "./input/2_2_146 83\n",
            "./input/2_1_145 84\n",
            "./input/2_1_144 85\n",
            "./input/2_1_143 86\n",
            "./input/2_1_141 87\n",
            "./input/2_1_142 88\n",
            "./input/2_1_137 89\n",
            "./input/2_1_138 90\n",
            "./input/2_1_134 91\n",
            "./input/2_1_136 92\n",
            "./input/2_1_140 93\n",
            "./input/2_1_135 94\n",
            "./input/2_1_139 95\n",
            "./input/2_1_133 96\n",
            "./input/2_1_132 97\n",
            "./input/2_1_131 98\n",
            "./input/2_1_128 99\n",
            "./input/2_1_129 100\n",
            "./input/2_1_130 101\n",
            "./input/2_1_127 102\n",
            "./input/2_1_126 103\n",
            "./input/2_1_123 104\n",
            "./input/2_1_124 105\n",
            "./input/2_1_121 106\n",
            "./input/2_1_125 107\n",
            "./input/2_1_122 108\n",
            "./input/2_1_120 109\n",
            "./input/2_1_119 110\n",
            "./input/2_1_118 111\n",
            "./input/2_1_115 112\n",
            "./input/2_1_117 113\n",
            "./input/2_1_116 114\n",
            "./input/2_1_113 115\n",
            "./input/2_1_114 116\n",
            "./input/1_4_112 116\n",
            "./input/1_4_111 117\n",
            "./input/1_4_106 118\n",
            "./input/1_4_107 119\n",
            "./input/1_4_110 120\n",
            "./input/1_4_109 121\n",
            "./input/1_4_105 122\n",
            "./input/1_4_108 123\n",
            "./input/1_3_97 124\n",
            "./input/1_3_99 124\n",
            "./input/1_3_98 125\n",
            "./input/1_3_95 126\n",
            "./input/1_3_90 127\n",
            "./input/1_3_93 128\n",
            "./input/1_3_96 129\n",
            "./input/1_3_91 130\n",
            "./input/1_3_92 131\n",
            "./input/1_3_94 132\n",
            "./input/1_3_88 133\n",
            "./input/1_3_87 134\n",
            "./input/1_3_89 135\n",
            "./input/1_3_82 135\n",
            "./input/1_3_85 136\n",
            "./input/1_3_81 137\n",
            "./input/1_3_86 138\n",
            "./input/1_3_84 139\n",
            "./input/1_3_83 140\n",
            "./input/1_3_80 141\n",
            "./input/1_3_79 142\n",
            "./input/1_3_77 143\n",
            "./input/1_3_78 144\n",
            "./input/1_3_73 145\n",
            "./input/1_3_71 146\n",
            "./input/1_3_75 147\n",
            "./input/1_3_74 148\n",
            "./input/1_3_72 149\n",
            "./input/1_3_70 150\n",
            "./input/1_3_76 151\n",
            "./input/1_3_69 152\n",
            "./input/1_3_67 153\n",
            "./input/1_3_68 154\n",
            "./input/1_3_63 155\n",
            "./input/1_3_66 156\n",
            "./input/1_3_65 157\n",
            "./input/1_3_62 158\n",
            "./input/1_3_64 159\n",
            "./input/1_3_61 160\n",
            "./input/1_3_60 161\n",
            "./input/1_3_103 162\n",
            "./input/1_3_59 163\n",
            "./input/1_3_104 164\n",
            "./input/1_2_58 165\n",
            "./input/1_2_57 166\n",
            "./input/1_2_55 167\n",
            "./input/1_2_56 168\n",
            "./input/1_3_100 169\n",
            "./input/1_3_101 170\n",
            "./input/1_3_102 171\n",
            "./input/1_2_52 172\n",
            "./input/1_2_53 173\n",
            "./input/1_2_54 174\n",
            "./input/1_2_51 174\n",
            "./input/1_2_50 175\n",
            "./input/1_2_49 176\n",
            "./input/1_2_46 177\n",
            "./input/1_2_45 178\n",
            "./input/1_2_48 179\n",
            "./input/1_2_44 180\n",
            "./input/1_2_43 181\n",
            "./input/1_2_42 182\n",
            "./input/1_2_40 183\n",
            "./input/1_2_39 184\n",
            "./input/1_2_41 185\n",
            "./input/1_2_37 186\n",
            "./input/1_2_36 187\n",
            "./input/1_2_35 188\n",
            "./input/1_2_38 189\n",
            "./input/1_2_33 189\n",
            "./input/1_2_32 190\n",
            "./input/1_2_34 191\n",
            "./input/1_2_29 192\n",
            "./input/1_2_31 193\n",
            "./input/1_2_30 194\n",
            "./input/1_2_22 195\n",
            "./input/1_2_27 196\n",
            "./input/1_2_25 197\n",
            "./input/1_2_26 198\n",
            "./input/1_2_23 199\n",
            "./input/1_2_24 200\n",
            "./input/1_2_28 201\n",
            "./input/1_1_9 202\n",
            "./input/1_1_7 203\n",
            "./input/1_1_8 203\n",
            "./input/1_1_6 204\n",
            "./input/1_1_4 205\n",
            "./input/1_1_5 206\n",
            "./input/1_1_20 207\n",
            "./input/1_1_21 208\n",
            "./input/1_1_3 209\n",
            "./input/1_1_16 210\n",
            "./input/1_1_19 211\n",
            "./input/1_1_15 212\n",
            "./input/1_1_17 213\n",
            "./input/1_1_2 214\n",
            "./input/1_1_14 215\n",
            "./input/1_1_18 215\n",
            "./input/1_1_12 216\n",
            "./input/1_1_13 217\n",
            "./input/1_1_11 218\n",
            "./input/1_1_10 219\n",
            "./input/1_1_1 220\n",
            "./input/6_5_1858 221\n",
            "./input/6_5_1859 222\n",
            "./input/6_5_1857 223\n",
            "./input/6_4_1853 223\n",
            "./input/6_4_1849 224\n",
            "./input/6_5_1856 225\n",
            "./input/6_4_1852 226\n",
            "./input/6_4_1846 227\n",
            "./input/6_4_1854 228\n",
            "./input/6_4_1847 229\n",
            "./input/6_4_1850 230\n",
            "./input/6_4_1855 231\n",
            "./input/6_4_1851 232\n",
            "./input/6_4_1843 233\n",
            "./input/6_4_1842 234\n",
            "./input/6_4_1837 235\n",
            "./input/6_4_1840 236\n",
            "./input/6_4_1841 237\n",
            "./input/6_4_1838 238\n",
            "./input/6_4_1844 239\n",
            "./input/6_4_1839 240\n",
            "./input/6_4_1836 241\n",
            "./input/6_4_1845 242\n",
            "./input/6_4_1835 243\n",
            "./input/6_4_1833 244\n",
            "./input/6_4_1834 245\n",
            "./input/6_4_1826 246\n",
            "./input/6_4_1832 247\n",
            "./input/6_4_1828 248\n",
            "./input/6_4_1830 249\n",
            "./input/6_4_1824 250\n",
            "./input/6_4_1831 251\n",
            "./input/6_4_1829 252\n",
            "./input/6_4_1823 252\n",
            "./input/6_3_1814 253\n",
            "./input/6_3_1820 254\n",
            "./input/6_3_1816 255\n",
            "./input/6_3_1819 256\n",
            "./input/6_3_1818 257\n",
            "./input/6_3_1821 258\n",
            "./input/6_3_1815 259\n",
            "./input/6_4_1822 260\n",
            "./input/6_3_1817 261\n",
            "./input/6_2_1805 262\n",
            "./input/6_3_1810 263\n",
            "./input/6_3_1807 264\n",
            "./input/6_2_1806 265\n",
            "./input/6_3_1809 266\n",
            "./input/6_3_1812 266\n",
            "./input/6_3_1808 266\n",
            "./input/6_2_1804 267\n",
            "./input/6_3_1811 268\n",
            "./input/6_3_1813 269\n",
            "./input/6_2_1801 269\n",
            "./input/6_2_1802 269\n",
            "./input/6_2_1803 270\n",
            "./input/6_2_1792 271\n",
            "./input/6_2_1799 272\n",
            "./input/6_2_1794 273\n",
            "./input/6_2_1797 274\n",
            "./input/6_2_1796 275\n",
            "./input/6_2_1800 276\n",
            "./input/6_2_1798 277\n",
            "./input/6_2_1788 278\n",
            "./input/6_2_1789 279\n",
            "./input/6_2_1790 280\n",
            "./input/6_2_1791 281\n",
            "./input/6_2_1785 282\n",
            "./input/6_2_1787 282\n",
            "./input/6_2_1781 283\n",
            "./input/6_2_1784 284\n",
            "./input/6_2_1786 285\n",
            "./input/6_2_1782 286\n",
            "./input/6_2_1776 287\n",
            "./input/6_2_1773 288\n",
            "./input/6_2_1775 289\n",
            "./input/6_2_1774 290\n",
            "./input/6_2_1771 291\n",
            "./input/6_2_1779 292\n",
            "./input/6_2_1772 293\n",
            "./input/6_2_1778 294\n",
            "./input/6_2_1780 295\n",
            "./input/6_2_1777 296\n",
            "./input/6_1_1761 297\n",
            "./input/6_2_1767 298\n",
            "./input/6_2_1763 299\n",
            "./input/6_2_1768 300\n",
            "./input/6_1_1762 301\n",
            "./input/6_2_1770 302\n",
            "./input/6_2_1765 303\n",
            "./input/6_2_1769 303\n",
            "./input/6_2_1764 304\n",
            "./input/6_2_1766 305\n",
            "./input/6_1_1754 306\n",
            "./input/6_1_1756 307\n",
            "./input/6_1_1760 308\n",
            "./input/6_1_1753 309\n",
            "./input/6_1_1758 310\n",
            "./input/6_1_1759 311\n",
            "./input/6_1_1757 312\n",
            "./input/6_9_1988 313\n",
            "./input/6_9_1983 314\n",
            "./input/6_9_1980 315\n",
            "./input/6_9_1986 316\n",
            "./input/6_9_1989 317\n",
            "./input/6_9_1982 318\n",
            "./input/6_9_1987 319\n",
            "./input/6_9_1985 320\n",
            "./input/6_9_1981 321\n",
            "./input/6_9_1984 322\n",
            "./input/6_9_1978 323\n",
            "./input/6_9_1979 324\n",
            "./input/6_9_1970 325\n",
            "./input/6_9_1975 326\n",
            "./input/6_9_1975/.ipynb_checkpoints 327\n",
            "./input/6_9_1974 327\n",
            "./input/6_9_1974/.ipynb_checkpoints 328\n",
            "./input/6_9_1971 328\n",
            "./input/6_9_1976 329\n",
            "./input/6_9_1973 330\n",
            "./input/6_9_1977 330\n",
            "./input/6_9_1972 331\n",
            "./input/6_9_1966 332\n",
            "./input/6_9_1962 333\n",
            "./input/6_9_1967 334\n",
            "./input/6_9_1965 335\n",
            "./input/6_9_1960 336\n",
            "./input/6_9_1968 337\n",
            "./input/6_9_1964 338\n",
            "./input/6_9_1969 339\n",
            "./input/6_9_1961 340\n",
            "./input/6_9_1959 341\n",
            "./input/6_9_1955 342\n",
            "./input/6_9_1950 343\n",
            "./input/6_9_1953 344\n",
            "./input/6_9_1952 345\n",
            "./input/6_9_1948 346\n",
            "./input/6_9_1957 347\n",
            "./input/6_9_1951 348\n",
            "./input/6_9_1956 349\n",
            "./input/6_9_1954 349\n",
            "./input/6_9_1949 350\n",
            "./input/6_8_1938 351\n",
            "./input/6_9_1941 352\n",
            "./input/6_9_1946 353\n",
            "./input/6_9_1943 354\n",
            "./input/6_9_1947 355\n",
            "./input/6_9_1942 356\n",
            "./input/6_9_1945 356\n",
            "./input/6_9_1939 357\n",
            "./input/6_9_1944 358\n",
            "./input/6_9_1940 359\n",
            "./input/6_8_1932 360\n",
            "./input/6_8_1935 361\n",
            "./input/6_8_1929 362\n",
            "./input/6_8_1931 363\n",
            "./input/6_8_1936 364\n",
            "./input/6_8_1928 365\n",
            "./input/6_8_1930 366\n",
            "./input/6_8_1933 367\n",
            "./input/6_8_1934 368\n",
            "./input/6_8_1937 369\n",
            "./input/6_8_1923 369\n",
            "./input/6_8_1919 370\n",
            "./input/6_8_1924 371\n",
            "./input/6_8_1925 372\n",
            "./input/6_8_1922 372\n",
            "./input/6_8_1920 373\n",
            "./input/6_8_1926 374\n",
            "./input/6_7_1918 375\n",
            "./input/6_8_1927 376\n",
            "./input/6_8_1921 377\n",
            "./input/6_7_1911 378\n",
            "./input/6_7_1917 379\n",
            "./input/6_7_1916 380\n",
            "./input/6_7_1910 381\n",
            "./input/6_7_1912 382\n",
            "./input/6_7_1913 383\n",
            "./input/6_7_1908 384\n",
            "./input/6_7_1914 385\n",
            "./input/6_7_1915 386\n",
            "./input/6_7_1909 387\n",
            "./input/6_7_1905 388\n",
            "./input/6_7_1900 389\n",
            "./input/6_7_1907 390\n",
            "./input/6_7_1906 391\n",
            "./input/6_7_1901 392\n",
            "./input/6_7_1899 393\n",
            "./input/6_7_1898 394\n",
            "./input/6_7_1903 395\n",
            "./input/6_7_1902 396\n",
            "./input/6_7_1904 397\n",
            "./input/6_6_1891 398\n",
            "./input/6_6_1888 399\n",
            "./input/6_6_1893 400\n",
            "./input/6_6_1894 401\n",
            "./input/6_7_1897 402\n",
            "./input/6_6_1890 403\n",
            "./input/6_6_1889 403\n",
            "./input/6_7_1895 404\n",
            "./input/6_6_1892 405\n",
            "./input/6_7_1896 406\n",
            "./input/6_6_1887 407\n",
            "./input/6_6_1879 407\n",
            "./input/6_6_1886 408\n",
            "./input/6_5_1878 408\n",
            "./input/6_6_1883 409\n",
            "./input/6_6_1885 410\n",
            "./input/6_6_1884 411\n",
            "./input/6_6_1882 412\n",
            "./input/6_6_1880 413\n",
            "./input/6_6_1881 414\n",
            "./input/6_5_1873 415\n",
            "./input/6_5_1867 416\n",
            "./input/6_5_1877 417\n",
            "./input/6_5_1872 417\n",
            "./input/6_5_1874 418\n",
            "./input/6_5_1876 419\n",
            "./input/6_5_1868 420\n",
            "./input/6_5_1870 421\n",
            "./input/6_5_1875 422\n",
            "./input/6_5_1871 423\n",
            "./input/6_5_1864 424\n",
            "./input/6_5_1863 425\n",
            "./input/6_5_1862 426\n",
            "./input/6_5_1865 427\n",
            "./input/6_5_1866 428\n",
            "./input/6_5_1860 429\n",
            "./input/6_5_1861 430\n",
            "431\n",
            "load dataset done\n",
            "load dataset done\n",
            "load dataset done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qaRiUj9dl00O"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2lGr01Unl00P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e328a07c-f2ca-495c-c09c-1ae0a40bfaca"
      },
      "source": [
        "vgg = models.vgg19().features.cuda()\n",
        "input_dim = 128\n",
        "summary(vgg, (3, input_dim, input_dim))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 64, 128, 128]           1,792\n",
            "              ReLU-2         [-1, 64, 128, 128]               0\n",
            "            Conv2d-3         [-1, 64, 128, 128]          36,928\n",
            "              ReLU-4         [-1, 64, 128, 128]               0\n",
            "         MaxPool2d-5           [-1, 64, 64, 64]               0\n",
            "            Conv2d-6          [-1, 128, 64, 64]          73,856\n",
            "              ReLU-7          [-1, 128, 64, 64]               0\n",
            "            Conv2d-8          [-1, 128, 64, 64]         147,584\n",
            "              ReLU-9          [-1, 128, 64, 64]               0\n",
            "        MaxPool2d-10          [-1, 128, 32, 32]               0\n",
            "           Conv2d-11          [-1, 256, 32, 32]         295,168\n",
            "             ReLU-12          [-1, 256, 32, 32]               0\n",
            "           Conv2d-13          [-1, 256, 32, 32]         590,080\n",
            "             ReLU-14          [-1, 256, 32, 32]               0\n",
            "           Conv2d-15          [-1, 256, 32, 32]         590,080\n",
            "             ReLU-16          [-1, 256, 32, 32]               0\n",
            "           Conv2d-17          [-1, 256, 32, 32]         590,080\n",
            "             ReLU-18          [-1, 256, 32, 32]               0\n",
            "        MaxPool2d-19          [-1, 256, 16, 16]               0\n",
            "           Conv2d-20          [-1, 512, 16, 16]       1,180,160\n",
            "             ReLU-21          [-1, 512, 16, 16]               0\n",
            "           Conv2d-22          [-1, 512, 16, 16]       2,359,808\n",
            "             ReLU-23          [-1, 512, 16, 16]               0\n",
            "           Conv2d-24          [-1, 512, 16, 16]       2,359,808\n",
            "             ReLU-25          [-1, 512, 16, 16]               0\n",
            "           Conv2d-26          [-1, 512, 16, 16]       2,359,808\n",
            "             ReLU-27          [-1, 512, 16, 16]               0\n",
            "        MaxPool2d-28            [-1, 512, 8, 8]               0\n",
            "           Conv2d-29            [-1, 512, 8, 8]       2,359,808\n",
            "             ReLU-30            [-1, 512, 8, 8]               0\n",
            "           Conv2d-31            [-1, 512, 8, 8]       2,359,808\n",
            "             ReLU-32            [-1, 512, 8, 8]               0\n",
            "           Conv2d-33            [-1, 512, 8, 8]       2,359,808\n",
            "             ReLU-34            [-1, 512, 8, 8]               0\n",
            "           Conv2d-35            [-1, 512, 8, 8]       2,359,808\n",
            "             ReLU-36            [-1, 512, 8, 8]               0\n",
            "        MaxPool2d-37            [-1, 512, 4, 4]               0\n",
            "================================================================\n",
            "Total params: 20,024,384\n",
            "Trainable params: 20,024,384\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.19\n",
            "Forward/backward pass size (MB): 77.81\n",
            "Params size (MB): 76.39\n",
            "Estimated Total Size (MB): 154.39\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2uu8pVbx0P2r",
        "outputId": "067ddaa9-4c1a-423f-cb67-b0feb2e3628f"
      },
      "source": [
        "resnet = models.resnet18().cuda()\n",
        "input_dim = 128\n",
        "summary(resnet, (3, input_dim, input_dim))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 64, 64]           9,408\n",
            "       BatchNorm2d-2           [-1, 64, 64, 64]             128\n",
            "              ReLU-3           [-1, 64, 64, 64]               0\n",
            "         MaxPool2d-4           [-1, 64, 32, 32]               0\n",
            "            Conv2d-5           [-1, 64, 32, 32]          36,864\n",
            "       BatchNorm2d-6           [-1, 64, 32, 32]             128\n",
            "              ReLU-7           [-1, 64, 32, 32]               0\n",
            "            Conv2d-8           [-1, 64, 32, 32]          36,864\n",
            "       BatchNorm2d-9           [-1, 64, 32, 32]             128\n",
            "             ReLU-10           [-1, 64, 32, 32]               0\n",
            "       BasicBlock-11           [-1, 64, 32, 32]               0\n",
            "           Conv2d-12           [-1, 64, 32, 32]          36,864\n",
            "      BatchNorm2d-13           [-1, 64, 32, 32]             128\n",
            "             ReLU-14           [-1, 64, 32, 32]               0\n",
            "           Conv2d-15           [-1, 64, 32, 32]          36,864\n",
            "      BatchNorm2d-16           [-1, 64, 32, 32]             128\n",
            "             ReLU-17           [-1, 64, 32, 32]               0\n",
            "       BasicBlock-18           [-1, 64, 32, 32]               0\n",
            "           Conv2d-19          [-1, 128, 16, 16]          73,728\n",
            "      BatchNorm2d-20          [-1, 128, 16, 16]             256\n",
            "             ReLU-21          [-1, 128, 16, 16]               0\n",
            "           Conv2d-22          [-1, 128, 16, 16]         147,456\n",
            "      BatchNorm2d-23          [-1, 128, 16, 16]             256\n",
            "           Conv2d-24          [-1, 128, 16, 16]           8,192\n",
            "      BatchNorm2d-25          [-1, 128, 16, 16]             256\n",
            "             ReLU-26          [-1, 128, 16, 16]               0\n",
            "       BasicBlock-27          [-1, 128, 16, 16]               0\n",
            "           Conv2d-28          [-1, 128, 16, 16]         147,456\n",
            "      BatchNorm2d-29          [-1, 128, 16, 16]             256\n",
            "             ReLU-30          [-1, 128, 16, 16]               0\n",
            "           Conv2d-31          [-1, 128, 16, 16]         147,456\n",
            "      BatchNorm2d-32          [-1, 128, 16, 16]             256\n",
            "             ReLU-33          [-1, 128, 16, 16]               0\n",
            "       BasicBlock-34          [-1, 128, 16, 16]               0\n",
            "           Conv2d-35            [-1, 256, 8, 8]         294,912\n",
            "      BatchNorm2d-36            [-1, 256, 8, 8]             512\n",
            "             ReLU-37            [-1, 256, 8, 8]               0\n",
            "           Conv2d-38            [-1, 256, 8, 8]         589,824\n",
            "      BatchNorm2d-39            [-1, 256, 8, 8]             512\n",
            "           Conv2d-40            [-1, 256, 8, 8]          32,768\n",
            "      BatchNorm2d-41            [-1, 256, 8, 8]             512\n",
            "             ReLU-42            [-1, 256, 8, 8]               0\n",
            "       BasicBlock-43            [-1, 256, 8, 8]               0\n",
            "           Conv2d-44            [-1, 256, 8, 8]         589,824\n",
            "      BatchNorm2d-45            [-1, 256, 8, 8]             512\n",
            "             ReLU-46            [-1, 256, 8, 8]               0\n",
            "           Conv2d-47            [-1, 256, 8, 8]         589,824\n",
            "      BatchNorm2d-48            [-1, 256, 8, 8]             512\n",
            "             ReLU-49            [-1, 256, 8, 8]               0\n",
            "       BasicBlock-50            [-1, 256, 8, 8]               0\n",
            "           Conv2d-51            [-1, 512, 4, 4]       1,179,648\n",
            "      BatchNorm2d-52            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-53            [-1, 512, 4, 4]               0\n",
            "           Conv2d-54            [-1, 512, 4, 4]       2,359,296\n",
            "      BatchNorm2d-55            [-1, 512, 4, 4]           1,024\n",
            "           Conv2d-56            [-1, 512, 4, 4]         131,072\n",
            "      BatchNorm2d-57            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-58            [-1, 512, 4, 4]               0\n",
            "       BasicBlock-59            [-1, 512, 4, 4]               0\n",
            "           Conv2d-60            [-1, 512, 4, 4]       2,359,296\n",
            "      BatchNorm2d-61            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-62            [-1, 512, 4, 4]               0\n",
            "           Conv2d-63            [-1, 512, 4, 4]       2,359,296\n",
            "      BatchNorm2d-64            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-65            [-1, 512, 4, 4]               0\n",
            "       BasicBlock-66            [-1, 512, 4, 4]               0\n",
            "AdaptiveAvgPool2d-67            [-1, 512, 1, 1]               0\n",
            "           Linear-68                 [-1, 1000]         513,000\n",
            "================================================================\n",
            "Total params: 11,689,512\n",
            "Trainable params: 11,689,512\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.19\n",
            "Forward/backward pass size (MB): 20.51\n",
            "Params size (MB): 44.59\n",
            "Estimated Total Size (MB): 65.29\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "czjso0Jzl00P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58c8d216-9ad8-4b3a-b3f8-9d7abad3cbd9"
      },
      "source": [
        "class nnModel(nn.Module):\n",
        "\n",
        "    def __init__(self, input_size, hidden_size, cnn_output_size=512*4*4):\n",
        "        \"\"\"\n",
        "        Initialize NN architecture.\n",
        "\n",
        "        Hyperparameters\n",
        "        ----------\n",
        "        input_dim: int\n",
        "            Input size in LSTM.\n",
        "        hidden_dim: int\n",
        "            Hidden size in LSTM.\n",
        "        \"\"\"\n",
        "\n",
        "        super(nnModel, self).__init__()\n",
        "\n",
        "        self.input_size = cnn_output_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.lstm1 = nn.LSTMCell(input_size=self.input_size, hidden_size=self.hidden_size).cuda()\n",
        "        self.dropout1 = nn.Dropout(0.4)\n",
        "        self.dropout2 = nn.Dropout(0.2) \n",
        "        ##############################################################################\n",
        "        # TODO: Adjust CNN Model                                                     #\n",
        "        ##############################################################################\n",
        "        self.cnn = models.resnet18(pretrained=True).cuda()\n",
        "        ##############################################################################\n",
        "        # TODO: Adjust CNN output size base on the summary function above            #\n",
        "        ##############################################################################\n",
        "        self.cnn_output_size = cnn_output_size\n",
        "        self.fc_cnn_lstm = nn.Linear(self.cnn_output_size, self.input_size).cuda()\n",
        "        self.fc_lstm_output = nn.Linear(self.hidden_size, 2).cuda()\n",
        "\n",
        "\n",
        "    def init_weights(self):\n",
        "        \"\"\"Initializing lstm weights.\"\"\"\n",
        "        \"\"\"TODO: Adjust initialization.\"\"\"\n",
        "        nn.init.xavier_uniform_(self.lstm1.weight_ih, gain=1.0).cuda()\n",
        "        nn.init.xavier_uniform_(self.lstm1.weight_hh, gain=1.0).cuda()\n",
        "        nn.init.constant_(self.lstm1.bias_ih, 0.0).cuda()\n",
        "        nn.init.constant_(self.lstm1.bias_hh, 0.0).cuda()\n",
        "\n",
        "    def init_hidden(self, N):\n",
        "        \"\"\"Initializing hidden states and cell states.\"\"\"\n",
        "        h_0 = torch.zeros(N, self.hidden_size).cuda()\n",
        "        c_0 = torch.zeros(N, self.hidden_size).cuda()\n",
        "        return h_0, c_0\n",
        "\n",
        "    def forward(self, img_sequence):\n",
        "        N,T,d,x,y = img_sequence.shape  # N is batchsize T is timestep, d = 3\n",
        "        #print(\"img_sequence\",img_sequence.size())\n",
        "        # declaring the initial hidden states and cell states\n",
        "        h_t, c_t = self.init_hidden(N)\n",
        "\n",
        "        for i in range(T):\n",
        "            img = img_sequence[:,i,:,:,:]   #N*Cin*Hin*Win\n",
        "            #print(img.shape)\n",
        "            img_features = self.cnn(img).view(-1,self.cnn_output_size)    #N*Cout*Hout*Wout\n",
        "            img_features = self.dropout1(img_features)\n",
        "            i_t = self.fc_cnn_lstm(img_features)\n",
        "            h_t,c_t = self.lstm1(i_t,(h_t,c_t))\n",
        "            #h_t,c_t = self.lstm1(img_features,(h_t,c_t))\n",
        "            \n",
        "        output = self.fc_lstm_output(h_t)\n",
        "\n",
        "        return output\n",
        "\n",
        "        # NOTE: Optional bbox sequence data\n",
        "        # input_size2 = hidden_size1\n",
        "        # hidden_size2 = hidden_size2\n",
        "        # lstm2 = nn.LSTMCell(input_size=input_size2,hidden_size=hidden_size2)\n",
        "        # h_t=c_t = torch.zeros(N, hidden_size2)#\n",
        "        # for i in range(T):\n",
        "        # input = (h + bbox_sequence[:,-i,:,:,:]).view(N,-1)\n",
        "        # h_t,c_t = lstm(input,(h_t,c_t))\n",
        "\n",
        "\n",
        "##############################################################################\n",
        "# TODO: Adjust Input_size and hidden_size here                               #\n",
        "##############################################################################\n",
        "model = nnModel(128 , 128, 1000).cuda()#.to(device)\n",
        "criterion = nn.CrossEntropyLoss().cuda() # Specify the loss layer\n",
        "print('Your network:')\n",
        "print(model)\n",
        "#print(summary(model, (BATCH_SIZE,SEQUENCE_SIZE,3,128,128))) # visualize your model "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Your network:\n",
            "nnModel(\n",
            "  (lstm1): LSTMCell(1000, 128)\n",
            "  (dropout1): Dropout(p=0.4, inplace=False)\n",
            "  (dropout2): Dropout(p=0.2, inplace=False)\n",
            "  (cnn): ResNet(\n",
            "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "    (layer1): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (layer2): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (layer3): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (layer4): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "    (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
            "  )\n",
            "  (fc_cnn_lstm): Linear(in_features=1000, out_features=1000, bias=True)\n",
            "  (fc_lstm_output): Linear(in_features=128, out_features=2, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "we3bK0YAl00Q"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_OHGrLzUl00R"
      },
      "source": [
        "lr = 5e-5\n",
        "weight_decay = 1\n",
        "num_epoch = 10\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr,\n",
        "                       weight_decay=weight_decay)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4wNAzc1ml00S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd1dfc5a-0c93-488b-a21c-09769a0e5de9"
      },
      "source": [
        "# %%time\n",
        "def train(model,trainloader, valloader, num_epoch = 10): # Train the model\n",
        "  print(\"Srain(model, tart training...\")\n",
        "  trn_loss_hist = []\n",
        "  trn_acc_hist = []\n",
        "  val_acc_hist = []\n",
        "  model.train() # Set the model to training mode\n",
        "  for i in range(num_epoch):\n",
        "    running_loss = []\n",
        "    print('-----------------Epoch = %d-----------------' % (i+1))\n",
        "    for batch, label in tqdm(trainloader):\n",
        "      batch = batch.to(device)\n",
        "      label = label.to(device)\n",
        "      #print(\"batch\",batch.size())\n",
        "      optimizer.zero_grad() # Clear gradients from the previous iteration\n",
        "      pred = model(batch) # This will call Network.forward() that you implement\n",
        "      loss = criterion(pred, label) # Calculate the loss\n",
        "      running_loss.append(loss.item())\n",
        "      loss.backward() # Backprop gradients to all tensors in the network\n",
        "      optimizer.step() # Update trainable weights\n",
        "    print(\"\\n Epoch {} loss:{}\".format(i+1,np.mean(running_loss)))\n",
        "\n",
        "    # Keep track of training loss, accuracy, and validation loss\n",
        "    trn_loss_hist.append(np.mean(running_loss))\n",
        "    trn_acc_hist.append(evaluate(model, trainloader))\n",
        "    print(\"\\n Evaluate on validation set...\")\n",
        "    val_acc_hist.append(evaluate(model, valloader))\n",
        "  print(\"Done!\")\n",
        "  return trn_loss_hist, trn_acc_hist, val_acc_hist\n",
        "\n",
        "def evaluate(model, loader): # Evaluate accuracy on validation / test set\n",
        "  model.eval() # Set the model to evaluation mode\n",
        "  correct = 0\n",
        "  with torch.no_grad(): # Do not calculate grident to speed up computation\n",
        "    for batch, label in tqdm(loader):\n",
        "      batch = batch.to(device)\n",
        "      label = label.to(device)\n",
        "      pred = model(batch)\n",
        "      correct += (torch.argmax(pred,dim=1)==label).sum().item()\n",
        "    acc = correct/len(loader.dataset)\n",
        "    print(\"\\n Evaluation accuracy: {}\".format(acc))\n",
        "    return acc\n",
        "    \n",
        "trn_loss_hist, trn_acc_hist, val_acc_hist = train(model, train_loader, \n",
        "                                                  val_loader, num_epoch)\n",
        "\n",
        "##############################################################################\n",
        "# TODO: Note down the evaluation accuracy on test set                        #\n",
        "##############################################################################\n",
        "print(\"\\n Evaluate on test set\")\n",
        "evaluate(model, test_loader);"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/20 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Srain(model, tart training...\n",
            "-----------------Epoch = 1-----------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:07<00:00,  2.68it/s]\n",
            "  5%|▌         | 1/20 [00:00<00:02,  7.06it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch 1 loss:0.674353438615799\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:02<00:00,  7.40it/s]\n",
            "  6%|▋         | 1/16 [00:00<00:01,  7.54it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Evaluation accuracy: 0.71\n",
            "\n",
            " Evaluate on validation set...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 16/16 [00:02<00:00,  7.45it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Evaluation accuracy: 0.6875\n",
            "-----------------Epoch = 2-----------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:07<00:00,  2.72it/s]\n",
            "  5%|▌         | 1/20 [00:00<00:02,  7.06it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch 2 loss:0.5922747373580932\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:02<00:00,  7.33it/s]\n",
            "  6%|▋         | 1/16 [00:00<00:02,  7.48it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Evaluation accuracy: 0.76\n",
            "\n",
            " Evaluate on validation set...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 16/16 [00:02<00:00,  7.29it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Evaluation accuracy: 0.7625\n",
            "-----------------Epoch = 3-----------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:07<00:00,  2.66it/s]\n",
            "  5%|▌         | 1/20 [00:00<00:02,  6.76it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch 3 loss:0.4755533471703529\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:02<00:00,  7.19it/s]\n",
            "  6%|▋         | 1/16 [00:00<00:02,  7.41it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Evaluation accuracy: 0.795\n",
            "\n",
            " Evaluate on validation set...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 16/16 [00:02<00:00,  7.22it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Evaluation accuracy: 0.75\n",
            "-----------------Epoch = 4-----------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:07<00:00,  2.64it/s]\n",
            "  5%|▌         | 1/20 [00:00<00:02,  6.96it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch 4 loss:0.4038394793868065\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:02<00:00,  7.22it/s]\n",
            "  6%|▋         | 1/16 [00:00<00:02,  7.43it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Evaluation accuracy: 0.9\n",
            "\n",
            " Evaluate on validation set...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 16/16 [00:02<00:00,  7.29it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Evaluation accuracy: 0.7875\n",
            "-----------------Epoch = 5-----------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:07<00:00,  2.68it/s]\n",
            "  5%|▌         | 1/20 [00:00<00:02,  6.99it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch 5 loss:0.33571621403098106\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:02<00:00,  7.34it/s]\n",
            "  6%|▋         | 1/16 [00:00<00:02,  7.50it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Evaluation accuracy: 0.925\n",
            "\n",
            " Evaluate on validation set...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 16/16 [00:02<00:00,  7.37it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Evaluation accuracy: 0.7625\n",
            "-----------------Epoch = 6-----------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:07<00:00,  2.71it/s]\n",
            "  5%|▌         | 1/20 [00:00<00:02,  7.17it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch 6 loss:0.30959229841828345\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:02<00:00,  7.39it/s]\n",
            "  6%|▋         | 1/16 [00:00<00:01,  7.50it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Evaluation accuracy: 0.93\n",
            "\n",
            " Evaluate on validation set...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 16/16 [00:02<00:00,  7.41it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Evaluation accuracy: 0.775\n",
            "-----------------Epoch = 7-----------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:07<00:00,  2.73it/s]\n",
            "  5%|▌         | 1/20 [00:00<00:02,  7.05it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch 7 loss:0.27007704600691795\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:02<00:00,  7.40it/s]\n",
            "  6%|▋         | 1/16 [00:00<00:01,  7.50it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Evaluation accuracy: 0.915\n",
            "\n",
            " Evaluate on validation set...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 16/16 [00:02<00:00,  7.44it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Evaluation accuracy: 0.76875\n",
            "-----------------Epoch = 8-----------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:07<00:00,  2.72it/s]\n",
            "  5%|▌         | 1/20 [00:00<00:02,  7.20it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch 8 loss:0.27229952737689017\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:02<00:00,  7.38it/s]\n",
            "  6%|▋         | 1/16 [00:00<00:02,  7.40it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Evaluation accuracy: 0.85\n",
            "\n",
            " Evaluate on validation set...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 16/16 [00:02<00:00,  7.37it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Evaluation accuracy: 0.76875\n",
            "-----------------Epoch = 9-----------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:07<00:00,  2.70it/s]\n",
            "  5%|▌         | 1/20 [00:00<00:02,  7.09it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch 9 loss:0.25173974484205247\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:02<00:00,  7.32it/s]\n",
            "  6%|▋         | 1/16 [00:00<00:01,  7.51it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Evaluation accuracy: 0.96\n",
            "\n",
            " Evaluate on validation set...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 16/16 [00:02<00:00,  7.38it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Evaluation accuracy: 0.75625\n",
            "-----------------Epoch = 10-----------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:07<00:00,  2.70it/s]\n",
            "  5%|▌         | 1/20 [00:00<00:02,  7.03it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch 10 loss:0.22079105749726297\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:02<00:00,  7.31it/s]\n",
            "  6%|▋         | 1/16 [00:00<00:01,  7.57it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Evaluation accuracy: 0.97\n",
            "\n",
            " Evaluate on validation set...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 16/16 [00:02<00:00,  7.34it/s]\n",
            " 25%|██▌       | 1/4 [00:00<00:00,  7.47it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Evaluation accuracy: 0.7625\n",
            "Done!\n",
            "\n",
            " Evaluate on test set\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  7.39it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Evaluation accuracy: 0.775\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U6zqBgJbl00S",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "outputId": "ef862512-f13c-4b9f-d05f-8ed41af6ff63"
      },
      "source": [
        "##############################################################################\n",
        "# TODO: Submit the accuracy plot                                             #\n",
        "##############################################################################\n",
        "# visualize the training / validation accuracies\n",
        "x = np.arange(num_epoch)\n",
        "# train/val accuracies for MiniVGG\n",
        "plt.figure()\n",
        "plt.plot(x, trn_acc_hist)\n",
        "plt.plot(x, val_acc_hist)\n",
        "plt.legend(['Training', 'Validation'])\n",
        "plt.xticks(x)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('fashion MNIST Classification')\n",
        "plt.gcf().set_size_inches(10, 5)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "-fsFaO8Gy9-z",
        "outputId": "48cc7863-3795-420a-b9bf-6a23d0dbf3a0"
      },
      "source": [
        "plt.figure()\n",
        "plt.plot(x, trn_loss_hist)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAfWklEQVR4nO3deXRV5b3/8fc3OUmAACEkYQwYAhFlHsIoIs60WvypiICzIuKE1rbW9t62V+2g4u312lKFglYtiAIOVFScsCogEEDAMAZECGMASYDMyXP/yEEDvwABkuwzfF5rZZFzzs7Zn3UW+awnz9772eacQ0REgl+E1wFERKRmqNBFREKECl1EJESo0EVEQoQKXUQkRPi82nFiYqJLSUnxavciIkFp2bJle51zSVW95lmhp6SkkJGR4dXuRUSCkpl9e7zXNOUiIhIiVOgiIiFChS4iEiJU6CIiIUKFLiISIlToIiIhQoUuIhIigq7Qt+w9zJPvr6O8XMv+iohUFnSF/sGaXTz36SYee2cNWstdROQHnl0perruPD+VPXlFTPniGxrV8/Gzyzp6HUlEJCAEXaGbGf9xxbkcKirlL59kERvjY9wF7b2OJSLiuaArdKgo9T9c3ZXDxWU88d46Gsb4uLH/WV7HEhHxVFAWOkBkhPHnEd0pKC7lN29/TWxMJFf3TPY6loiIZ4LuoGhlUZER/HV0LwakJvDzmauYl7nL60giIp4J6kIHqBcVyd9vTqdbchz3T1/B5xtzvI4kIuKJoC90gNgYH/+4tS+pSbGMfXkZGVv2ex1JRKTOhUShA8Q1iOKVO/rRMq4et724lK+353odSUSkToVMoQMkNYrhn2P60bh+FDe/sISsPQe9jiQiUmdCqtABWjWpz7Qx/YiMMG6Yspht+/O9jiQiUidCrtABUhJj+ecd/SgqLWf0lC/ZlVvodSQRkVoXkoUO0LFFI166rS/7DxVz49TF7D9c7HUkEZFaFbKFDtC9TROm3tqHbfvzufmFxeQVlngdSUSk1oR0oQP0T03g+Zt6s37XQW5/cSn5xaVeRxIRqRUhX+gAF3ZsxjPX92T51u+465VlFJWWeR1JRKTGhUWhA1zRrSVPXNuNzzfuZfyrKygtK/c6kohIjQqbQgcYkd6G3/2kE/Myd/PwrFW665GIhJSgXW3xdN12XjsOF5Xy9AcbiI3x8dhVnTEzr2OJiJyxsCt0gHsv7MDBolIm/XszDev5+OXQc7yOJCJyxsKy0M2MR4aew6HCUp77dBMNY3zce2EHr2OJiJyRsCx0qCj1x6/qQn5xGRPmradhjI9bBqZ4HUtE5LSFbaEDREQYE4Z343BRKb+bk0lsjI/hvXXXIxEJTmF1lktVfJER/GV0T85PS+ThWSt5b/VOryOJiJyWsC90gBhfJJNu6k3PtvGMn7GCT9fv8TqSiMgpU6H7NYj28cKtfTi7eSPG/XMZizfv8zqSiMgpUaFXElc/ipdv70vrJvW546UMVmUf8DqSiEi1qdCPkdAwhmlj+hMfW3HXo/W7dNcjEQkOKvQqtIirx7Q7+hMdGcGNUxezZe9hryOJiJxUtQrdzIaa2XozyzKzR46zzQgzW2NmmWY2vWZj1r22CQ2YNqYfpWXl3DBlMTtzC7yOJCJyQictdDOLBCYCPwI6AaPMrNMx26QBvwLOc851Bh6shax1Lq15I16+vR95BSXcMGUxew8VeR1JROS4qjNC7wtkOec2O+eKgRnAVcdscycw0Tn3HYBzLmTO++uaHMcLt/Vhx4ECbpq6hNx83fVIRAJTdQq9NbCt0uNs/3OVnQ2cbWYLzOxLMxtaUwEDQZ+Upky+KZ1New5x2z+WcLhIdz0SkcBTUwdFfUAaMAQYBfzdzJocu5GZjTWzDDPLyMnJqaFd143BZyfx7KierMzOZewrGRSW6K5HIhJYqlPo24E2lR4n+5+rLBuY45wrcc59A2ygouCP4pyb7JxLd86lJyUlnW5mzwzt0oIJw7uxIGsf901fQYnueiQiAaQ6hb4USDOzdmYWDYwE5hyzzVtUjM4xs0QqpmA212DOgHFNr2Qev6ozH63dzSOzV3sdR0TkeyctdOdcKXAfMA9YC7zunMs0s8fMbJh/s3nAPjNbA8wHfuGcC9lr528akML4i9OYvTybuau0mJeIBAZzzpv7aqanp7uMjAxP9l0TSsvKuea5hWR/V8CHPx1MQsMYryOJSBgws2XOufSqXtOVoqfJFxnB09d151BhKb+dk+l1HBERFfqZOLt5Ix64JI25q3byrtZRFxGPqdDP0F2DU+naOo7fvPU1+w8Xex1HRMKYCv0MHZl6ySss4bdvf+11HBEJYyr0GtCxRSMeuDiNd1bt1C3sRMQzKvQactcF7enSujG/eVtTLyLiDRV6DYnyT73kFpTwXzrrRUQ8oEKvQee0aMz4i9KYs3IH73+9y+s4IhJmVOg1bNyQ9nRu1Zj/fOtrvtPUi4jUIRV6DTsy9XIgv5j/+pemXkSk7qjQa8G5LRtz/0VpvP3VDuZlaupFROqGCr2W3HNhezq1bMx/vPk1B/I19SIitU+FXksqT708+q81XscRkTCgQq9FnVo15r6LOvDmiu18uGa313FEJMSp0GvZPUM6cG7Lxvz6zdWaehGRWqVCr2XRvgievq4b3x0u5jFNvYhILVKh14HOreK458IOvLFiOx9p6kVEaokKvY7cd2EHzmnRiF+/uZrc/BKv44hICFKh15GKqZfu7DtczKPv6IIjEal5KvQ61KV1HPcOac8by7fz8VpNvYhIzVKh17H7LkrT1IuI1AoVeh2L9kUwYXh39h4q5vG5OutFRGqOCt0DXZPjuPuC9sxals38dXu8jiMiIUKF7pH7L+5Ax+aNeOSNVeQWaOpFRM6cCt0jMb5IJlzXjb2Hivn9O5p6EZEzp0L3ULfkJoy7IJWZy7KZv15TLyJyZlToHht/cRppzRryq9mrySvU1IuInD4VusdifJE8fV13cg4V8Yd31nodR0SCmAo9AHRv04S7BqfyWsY2PtXUi4icJhV6gHjgEv/UyxuaehGR06NCDxAVZ710Z3deIX+cq6kXETl1KvQA0qNNE8YObs+Mpdv4bEOO13FEJMio0APMg5ek0T4plkdmr+Kgpl5E5BSo0ANMvaiKs1525RXyx3c19SIi1adCD0A928Zz5+BUXl2iqRcRqb5qFbqZDTWz9WaWZWaPVPH6rWaWY2Zf+b/G1HzU8PLTS86mfVIsv3pjtaZeRKRaTlroZhYJTAR+BHQCRplZpyo2fc0518P/NaWGc4adelEVZ73szC3gT++t8zqOiASB6ozQ+wJZzrnNzrliYAZwVe3GEoBebeMZc34q0xdv5YuNe72OIyIBrjqF3hrYVulxtv+5Y11rZqvMbJaZtanqjcxsrJllmFlGTo7mhqvjoUvPJjUpll/OXsWholKv44hIAKupg6L/AlKcc92AD4GXqtrIOTfZOZfunEtPSkqqoV2HtnpRkUwY3p0duQX8SWe9iMgJVKfQtwOVR9zJ/ue+55zb55wr8j+cAvSumXgC0PuseMYMase0xVtZkKWpFxGpWnUKfSmQZmbtzCwaGAnMqbyBmbWs9HAYoKFkDfvZZR1JTYzl4VmaehGRqp200J1zpcB9wDwqivp151ymmT1mZsP8m403s0wzWwmMB26trcDhql5UJE8N78aO3AKe1FkvIlIFc855suP09HSXkZHhyb6D2ePvrGHqF98wfUw/BnZI9DqOiNQxM1vmnEuv6jVdKRpkfn5ZR9olxvLw7FUc1tSLiFSiQg8y9aMrpl62Hyjgyfc19SIiP1ChB6E+KU25bWA7Xl70LYs27fM6jogECBV6kPrF5R05K6EBD89eSX6xpl5ERIUetOpHV1xwlP1dAb9+YzVl5d4c3BaRwKFCD2J92zXloUvO5q2vdnDvtOUUlZZ5HUlEPKRCD3L3X5zGb67sxPuZu7j9H0t10ZFIGFOhh4A7BrXjv6/rzpeb93PD379k/+FiryOJiAdU6CHi2t7JPH9jb9buOsiISYvYmVvgdSQRqWMq9BByaafmvHx7X3bnFjL8uUVsyjnkdSQRqUMq9BDTPzWBV8f2p7CkjBHPL+Lr7bleRxKROqJCD0FdWscxc9wA6kVFMnLyl7r4SCRMqNBDVGpSQ2bdPYCWcfW45cUlfJC5y+tIIlLLVOghrGVcfV6/awDntmzM3dOWM2tZtteRRKQWqdBDXHxsNNPH9GNAagI/n7mSKZ9v9jqSiNQSFXoYiI3xMfXWdH7ctQW/n7uWCfPW4dU6+CJSe3xeB5C6EeOL5C+jehFX/2smzt/Ed/klPH5VFyIjzOtoIlJDVOhhJDLC+OPVXYhvEMXfPt1EbkEJ/zOiB9E+/aEmEgpU6GHGzHh46DnEN4jmD++uJa+ghOdv7E1sjP4riAQ7Dc3C1J2DU3lqeDcWZO3lxqmLOZCv9V9Egp0KPYyNSG/Dczf2JnNHHiMmLWJXbqHXkUTkDKjQw9zlnVvwj9v6sONAIcOfX8g3ew97HUlETpMKXRjYPpFX7+xPfnEZ1z2/kMwdWv9FJBip0AWArskV679ER0YwctKXLPlmv9eRROQUqdDle+2TGjLr7oE0axzDTVMX8/Ha3V5HEpFToEKXo7RqUp+Z4wbSsUUjxr6yjDdXaP0XkWChQpf/T9PYaKbf2Z9+7Zry09dW8uKCb7yOJCLVoEKXKjWM8fHCrX24vHNzHv3XGv784Qat/yIS4FToclz1oiKZOLoX16e34dmPN/K7OZmUl6vURQKVrveWE/JFRvDEtV1p0iCKSZ9t5kB+CU9f113rv4gEIBW6nJSZ8asfn0t8bDRPvLeOvMISnruhN/WjI72OJiKVaJgl1TbugvY8cU1XPtuQw41TF5ObX+J1JBGpRIUup2Rk37ZMHN2L1dm5XD95EXvytP6LSKBQocsp+1HXlrxwax+27s9n+POL2Lov3+tIIoIKXU7ToLREpt/Zn4OFJVz7/ELW7szzOpJI2KtWoZvZUDNbb2ZZZvbICba71sycmaXXXEQJVD3aNGHmuAFEmnH9pEUs3aL1X0S8dNJCN7NIYCLwI6ATMMrMOlWxXSPgAWBxTYeUwNWhWSNm3T2AxIYx3DBlMe+u3ul1JJGwVZ0Rel8gyzm32TlXDMwArqpiu8eBJwEdJQszyfENmH33QLq2juPe6cuZ8vlmXVUq4oHqFHprYFulx9n+575nZr2ANs65uSd6IzMba2YZZpaRk5NzymElcMXHRjNtTD+Gdm7B7+eu5dF/raFMV5WK1KkzPihqZhHAn4GfnWxb59xk51y6cy49KSnpTHctAebIUgF3DGrHPxZu4Z5pyygsKfM6lkjYqE6hbwfaVHqc7H/uiEZAF+BTM9sC9Afm6MBoeIqIMH5zZSd+e2UnPlizm1F//5L9h3UDapG6UJ1CXwqkmVk7M4sGRgJzjrzonMt1ziU651KccynAl8Aw51xGrSSWoHD7oHY8d0Mv1uzI45q/LWCL7lUqUutOWujOuVLgPmAesBZ43TmXaWaPmdmw2g4owWtol5ZMv7MfuQUlXPPcQlZs/c7rSCIhzbw6GyE9Pd1lZGgQHw425xzi1heXsudgIc+O7MllnVt4HUkkaJnZMudclVPaulJUal1qUkPeuGcgHVs05q5/LuOlhVu8jiQSklToUicSG8Yw487+XHxOc343J5M/vrtWN8sQqWEqdKkz9aMjmXRTb24ecBaTP9vM+BkrdFqjSA3SDS6kTkVGGI8O60zrJvX503vr2JNXxOSbe9OkQbTX0USCnkboUufMjLsuaM+zo3ry1bYDXPvcQrbt1xK8ImdKhS6eGda9Fa/c0Zecg0Vc/beFrM7O9TqSSFBToYun+qUm8MY9A4nxRTBi0iLmr9vjdSSRoKVCF891aNaIN+8ZSPtmsYx5OYPpi7d6HUkkKKnQJSA0a1yP18YO4Py0RH795momzFunJXhFTpEKXQJGbIyPKTenM7JPGybO38RDr6+kuLTc61giQUOnLUpA8UVG8KdrupIcX5+nP9jArtxCnr+pN3H1o7yOJhLwNEKXgGNm3HdRGn8e0Z2lW/Zz3fML2XGgwOtYIgFPhS4B65peybx0e192Hijk6r8tYM2OPK8jiQQ0FboEtPM6JDLz7gEYxohJi/h8o25dKHI8KnQJeOe0aMyb9w4kOb4+t724lJkZ207+QyJhSIUuQaFlXH1mjhtA/9QEfjFrFc98tEGnNYocQ4UuQaNRvSheuLUP1/ZK5pmPNvLwrFWUlOm0RpEjdNqiBJVoXwRPX9eN1vH1efbjjezKK+RvN/SiUT2d1iiiEboEHTPjoUvP5slru7Jw0z5GTPqS3XmFXscS8ZwKXYLW9X3aMvWWdLbuO8zVExewYfdBryOJeEqFLkFtSMdmvHbXAErKHdc+t5CFm/Z6HUnEMyp0CXpdWsfx5j0Dad64Hre8sITxr65gXuYu3d5Owo4OikpISI5vwOxxA5nwwTreXb2LOSt30DDGx6WdmnNF15acf3YiMb5Ir2OK1Crz6lze9PR0l5GR4cm+JbSVlpWzaPM+5q7ayfuZuziQX0KjGB+Xdm7Old1aMqhDEtE+/XEqwcnMljnn0qt8TYUuoaykrJwFWXuZu2on8zJ3kVdYSuN6Pi7v3IIrurXkvA6JREWq3CV4qNBFgOLSinJ/Z9VOPlizi4OFpTRpEMXlnSrKfWD7BHwqdwlwKnSRYxSVlvH5hr3MXb2TD9fs5lBRKfENohjapSVXdmtJv3ZNVe4SkFToIidQWFLGZxtymLt6Jx+t2c3h4jISYqMZ2qVi5N6vXQKREeZ1TBFAhS5SbYUlZXy6fg/vrNrJx2v3UFBSRmLDGH7ctQVXdG1JekpTlbt4SoUuchoKisuYv34Pc1ft5ON1uyksKadZoxh+3LUlV3RrSe+28USo3KWOqdBFztDholI+WVdR7vPX76GotJwWjet9X+492zRRuUudUKGL1KBDRaV8vHY3c1ft5NMNORSXltMq7ody79GmCWYqd6kdKnSRWnKwsISP/OX+7w05lJQ5Wjepz0+6t+L281Jo1rie1xElxKjQRepAbkEJH63ZzdzVFeXuizBu6n8W44a0J7FhjNfxJESccaGb2VDgf4FIYIpz7oljXh8H3AuUAYeAsc65NSd6TxW6hLKt+/J59pONvLE8mxhfJLcMTGHs4FSaxkZ7HU2C3BkVuplFAhuAS4FsYCkwqnJhm1lj51ye//thwD3OuaEnel8VuoSDzTmHePbjjby9cgcNoiK5fVA7xgxKJa6B7rAkp+dEhV6dS+H6AlnOuc3OuWJgBnBV5Q2OlLlfLKC794oAqUkNeWZkTz54cDBDzmnGXz7JYtCTn/DMRxvIKyzxOp6EmOoUemtgW6XH2f7njmJm95rZJuApYHxVb2RmY80sw8wycnJyTievSFBKa96IiaN78f6D5zOwQwLPfLSR85+cz8T5WRwqKvU6noSIGluswjk30TnXHvgl8J/H2Waycy7dOZeelJRUU7sWCRrntGjMpJvSeef+QfRJiWfCvPUMfmo+k/69ifxiFbucmeoU+nagTaXHyf7njmcG8P/OJJRIqOvSOo4pt/ThrXvPo2vrOP703joGPzWfKZ9v1p2W5LRVp9CXAmlm1s7MooGRwJzKG5hZWqWHVwAbay6iSOjq0aYJL93el1njBtCxRSN+P3ctg5+az0sLt1BUqmKXU3PSQnfOlQL3AfOAtcDrzrlMM3vMf0YLwH1mlmlmXwEPAbfUWmKREJSe0pRpY/ozY2x/UhJj+d2cTIZM+JRpi7+luLTc63gSJHRhkUiAcc6xcNM+/vuD9SzfeoDk+PqMvyiNq3u11t2VRFeKigQj5xz/3pDD/3y4gZXZuZyV0IDxF6VxVY9WuvlGGDvT89BFxANmxpCOzXjr3vOYeks6DWN8/GzmSi575jPe/mo7ZeW63EOOpkIXCXBmxsXnNued+wfx/I29iYqI4IEZXzH0mc94d/VOylXs4qdCFwkSZsbQLi1474Hz+evonjjgnmnL+fGznzMvcxdeTZ9K4FChiwSZiAjjym6tmPfgYJ65vgdFpeXc9coyfvLXL/hk3W4VexjTQVGRIFdaVs6bK7bz7Ccb2ba/gB5tmvDQpWdzflpird9oo6zcUVRaRnFpOcWl5RT5vyq+9z9fVk5iwxg6Nm+kuzrVAJ3lIhIGSsrKmb0sm798ksX2AwWknxXP6H5tiTD7vmCL/AVbVFLx71HFW6mMj2xT5N+m+MjPHvPzp3JgNiE2moEdEhnUIYGB7RNp07RBLX4aoUuFLhJGikrLeD0jm4mfZLErr/C420VFGtGREUT7IojxRfr/rXj8w/eRREdGEBMVQUxkRBXbVPzckW0q/vX/TKVtv92Xz4KsvXyRtZc9B4sAOCuhAed1SGRQh0QGpCYQr7Xiq0WFLhKGCkvK2LLv8PelfaSAY/wF7MX0h3OOrD2H+CJrLwuy9vHl5n0cKirFDLq0imNghwQGdUikT0pT6kVF1nm+YKBCF5GAVFpWzsrs3O9H7yu2fkdJmSPaF0H6WfHfj+C7tI4jUvPvgApdRIJEfnEpS77Z7y/4fazdWXHvnMb1fAxoXzF6P69DIu0SY2v9gG+gOlGh++o6jIjI8TSI9jGkYzOGdGwGwN5DRSzctI8FGytG8PMydwPQKq6e/wBrIgM7JNCsUT0vYwcMjdBFJCg459i6P98//76XhZv2cSC/4jZ+HZs3qpieSUugb7sEGsaE7lhVUy4iEnLKyh1rduSxYFNFwS/5Zj9FpeX4IowebZr4Cz6RHm2ahNQqlSp0EQl5hSVlLP/2u+9H8Ku351LuIDY6kn6pCQxsn8DlnVsE/fnvKnQRCTu5+SUs2ryPBf6C37z3MGZwfloSo/u24eJzmwflyF2FLiJhb9v+fGYvz+a1pdvYmVtIYsMYRqQnM7JPW9omBM+oXYUuIuJXWlbOvzfk8OqSrXyybg/lDs5PS2R037Zc0inwR+0qdBGRKuzMLeD1pdm8tnQrO/yj9uvSkxnZpw1nJcR6Ha9KKnQRkRMoK3d8tiGH6f5Re1m5Y1CHREb1bculnZoT7QucUbsKXUSkmnblFvJ6xjZeW7qN7QcKSIiNZnh6MqP6tCUl0ftRuwpdROQUlZU7PtuYw6uLt/Kxf9Q+sH0Co/q25bLOzYnxebN4mApdROQM7M4rZGbGNl5dUjFqbxobzfDeFXPtqUkN6zSLCl1EpAaUlTu+yNrLq4u38uHa3ZSVOwakJjCqX1sur6NRuwpdRKSG7ckrZOaybF5dspXs7wqIbxBVMWrv25b2tThqV6GLiNSS8iOj9iVb+XDNbkrLHf3aNWV0v7Zc3rlFjd+oQ4UuIlIH9hwsZNaybGYs2cbW/fnEN4ji2l4Vo/YOzWpm1K5CFxGpQ+XljgWbKkbtH2RWjNr7tmvK6L5tGdrlzEbtKnQREY/kHCyqGLUv3cq3+/Jp0iCKR4d15qoerU/r/XTHIhERjyQ1iuHuIe25a3AqizbvY/qSrSTH16+VfanQRUTqQESEcZ7/nqi1to9ae2cREalTKnQRkRChQhcRCREqdBGREFGtQjezoWa23syyzOyRKl5/yMzWmNkqM/vYzM6q+agiInIiJy10M4sEJgI/AjoBo8ys0zGbrQDSnXPdgFnAUzUdVERETqw6I/S+QJZzbrNzrhiYAVxVeQPn3HznXL7/4ZdAcs3GFBGRk6lOobcGtlV6nO1/7njuAN6r6gUzG2tmGWaWkZOTU/2UIiJyUjV6YZGZ3QikAxdU9bpzbjIw2b9tjpl9e5q7SgT2nubPhiJ9HkfT5/EDfRZHC4XP47jHKKtT6NuBNpUeJ/ufO4qZXQL8B3CBc67oZG/qnEuqxr6rZGYZx1vLIBzp8ziaPo8f6LM4Wqh/HtWZclkKpJlZOzOLBkYCcypvYGY9gUnAMOfcnpqPKSIiJ3PSQnfOlQL3AfOAtcDrzrlMM3vMzIb5N5sANARmmtlXZjbnOG8nIiK1pFpz6M65d4F3j3nut5W+v6SGc53M5DreX6DT53E0fR4/0GdxtJD+PDxbD11ERGqWLv0XEQkRKnQRkRARdIV+snVlwoWZtTGz+f41dDLN7AGvMwUCM4s0sxVm9o7XWbxmZk3MbJaZrTOztWY2wOtMXjGzn/p/T742s1fNrJ7XmWpDUBV6NdeVCRelwM+cc52A/sC9YfxZVPYAFWdjCfwv8L5z7hygO2H6uZhZa2A8FetNdQEiqTj9OuQEVaFTjXVlwoVzbqdzbrn/+4NU/LKe3l1nQ4SZJQNXAFO8zuI1M4sDBgNTAZxzxc65A96m8pQPqG9mPqABsMPjPLUi2Ar9VNeVCQtmlgL0BBZ7m8RzzwAPA+VeBwkA7YAc4EX/FNQUM4v1OpQXnHPbgaeBrcBOINc594G3qWpHsBW6HMPMGgKzgQedc3le5/GKmV0J7HHOLfM6S4DwAb2A55xzPYHDQFgeczKzeCr+km8HtAJi/etOhZxgK/RqrSsTLswsiooyn+ace8PrPB47DxhmZluomIq7yMz+6W0kT2UD2c65I3+1zaKi4MPRJcA3zrkc51wJ8AYw0ONMtSLYCv2k68qECzMzKuZH1zrn/ux1Hq85537lnEt2zqVQ8f/iE+dcSI7CqsM5twvYZmYd/U9dDKzxMJKXtgL9zayB//fmYkL0AHGNLp9b25xzpWZ2ZF2ZSOAF51ymx7G8ch5wE7DazL7yP/dr/zINIgD3A9P8g5/NwG0e5/GEc26xmc0CllNxdtgKQnQJAF36LyISIoJtykVERI5DhS4iEiJU6CIiIUKFLiISIlToIiIhQoUuIhIiVOgiIiHi/wDJdq7cdWMf6QAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}